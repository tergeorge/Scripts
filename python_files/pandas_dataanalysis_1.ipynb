{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gCAPWR2s3nzA"
      },
      "source": [
        "\n",
        "In this question you will write Python code for processing, analyzing and understanding the social network **Reddit** (www.reddit.com). Reddit is a platform that allows users to upload posts and comment on them, and is divided in _subreddits_, often covering specific themes or areas of interest (for example, [world news](https://www.reddit.com/r/worldnews/), [ukpolitics](https://www.reddit.com/r/ukpolitics/) or [nintendo](https://www.reddit.com/r/nintendo)). You are provided with a subset of Reddit with posts from Covid-related subreddits (e.g., _CoronavirusUK_ or _NoNewNormal_), as well as randomly selected subreddits (e.g., _donaldtrump_ or _razer_).\n",
        "\n",
        "The `csv` dataset you are provided contains one row per post, and has information about three entities: **posts**, **users** and **subreddits**. The column names are self-explanatory: columns starting with the prefix `user_` describe users, those starting with the prefix `subr_` describe subreddits, the `subreddit` column is the subreddit name, and the rest of the columns are post attributes (`author`, `posted_at`, `title` and post text - the `selftext` column-, number of comments - `num_comments`, `score`, etc.).\n",
        "\n",
        "In this exercise, you are asked to perform a number of operations to gain insights from the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pm74v1u4d6G",
        "outputId": "8c1c68e9-2cd0-48fa-bb3e-12ae6089469b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# suggested imports\n",
        "import pandas as pd\n",
        "from nltk.tag import pos_tag\n",
        "import re\n",
        "from collections import defaultdict,Counter\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "tqdm.pandas()\n",
        "from ast import literal_eval\n",
        "# nltk imports, note that these outputs may be different if you are using colab or local jupyter notebooks\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "WfNsDQ253nzJ"
      },
      "outputs": [],
      "source": [
        "from urllib import request\n",
        "import pandas as pd\n",
        "module_url = f\"https://raw.githubusercontent.com/luisespinosaanke/cmt309-portfolio/master/data_portfolio_21.csv\"\n",
        "df = pd.read_csv(module_url, encoding='utf-8')\n",
        "#module_name = module_url.split('/')[-1]\n",
        "#print(f'Fetching {module_url}')\n",
        "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
        "#with request.urlopen(module_url).read().decode('utf-8') as f, open(module_name,'w') as outf:\n",
        " # a = f.read()\n",
        "  #outf.write(a.decode('utf-8'))\n",
        "\n",
        "\n",
        "#df = pd.read_csv('data_portfolio_21.csv')\n",
        "# this fills empty cells with empty strings\n",
        "#df = df.fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "CNfbxg2X3nzK",
        "outputId": "2c81b5dc-d03d-473d-eca4-1030b6727df5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5217f0fe-2da0-41f4-9ac4-affb56adea97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>posted_at</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>selftext</th>\n",
              "      <th>subr_created_at</th>\n",
              "      <th>subr_description</th>\n",
              "      <th>subr_faved_by</th>\n",
              "      <th>subr_numb_members</th>\n",
              "      <th>subr_numb_posts</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>total_awards_received</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>user_num_posts</th>\n",
              "      <th>user_registered_at</th>\n",
              "      <th>user_upvote_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-08-17 20:26:04</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>BREAKING: Trump to begin hiding in mailboxes t...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-07-06 17:01:48</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>Joe Biden's America</td>\n",
              "      <td>0</td>\n",
              "      <td>0.67</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-09-09 02:29:02</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>4 more years and we can erase his legacy for g...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-06-23 23:02:39</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>Revelation 9:6 [Transhumanism: The New Religio...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-08-07 04:13:53</td>\n",
              "      <td>32</td>\n",
              "      <td>622</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>LOOK HERE, FAT</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5217f0fe-2da0-41f4-9ac4-affb56adea97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5217f0fe-2da0-41f4-9ac4-affb56adea97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5217f0fe-2da0-41f4-9ac4-affb56adea97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       author            posted_at  num_comments  score selftext  \\\n",
              "0  -Howitzer-  2020-08-17 20:26:04            19      1      NaN   \n",
              "1  -Howitzer-  2020-07-06 17:01:48             1      3      NaN   \n",
              "2  -Howitzer-  2020-09-09 02:29:02             3      1      NaN   \n",
              "3  -Howitzer-  2020-06-23 23:02:39             2      1      NaN   \n",
              "4  -Howitzer-  2020-08-07 04:13:53            32    622      NaN   \n",
              "\n",
              "  subr_created_at              subr_description  \\\n",
              "0      2009-04-29  Subreddit about Donald Trump   \n",
              "1      2009-04-29  Subreddit about Donald Trump   \n",
              "2      2009-04-29  Subreddit about Donald Trump   \n",
              "3      2009-04-29  Subreddit about Donald Trump   \n",
              "4      2009-04-29  Subreddit about Donald Trump   \n",
              "\n",
              "                                       subr_faved_by  subr_numb_members  \\\n",
              "0  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "1  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "2  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "3  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "4  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "\n",
              "   subr_numb_posts    subreddit  \\\n",
              "0           796986  donaldtrump   \n",
              "1           796986  donaldtrump   \n",
              "2           796986  donaldtrump   \n",
              "3           796986  donaldtrump   \n",
              "4           796986  donaldtrump   \n",
              "\n",
              "                                               title  total_awards_received  \\\n",
              "0  BREAKING: Trump to begin hiding in mailboxes t...                      0   \n",
              "1                                Joe Biden's America                      0   \n",
              "2  4 more years and we can erase his legacy for g...                      0   \n",
              "3  Revelation 9:6 [Transhumanism: The New Religio...                      0   \n",
              "4                                     LOOK HERE, FAT                      0   \n",
              "\n",
              "   upvote_ratio  user_num_posts user_registered_at  user_upvote_ratio  \n",
              "0          1.00            4661         2012-11-09          -0.658599  \n",
              "1          0.67            4661         2012-11-09          -0.658599  \n",
              "2          1.00            4661         2012-11-09          -0.658599  \n",
              "3          1.00            4661         2012-11-09          -0.658599  \n",
              "4          0.88            4661         2012-11-09          -0.658599  "
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lyQyR27z48nr"
      },
      "source": [
        "## P1.1 - Text data processing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kLUtCUL853Ln"
      },
      "source": [
        "### P1.1.1 - Faved by as lists\n",
        "\n",
        "The column `subr_faved_by` contains an array of values (names of redditors who added the subreddit to which the current post was submitted), but unfortunately they are in text format, and you would not be able to process them properly without converting them to a suitable python type. You must convert these string values to Python lists, going from\n",
        "\n",
        "```python\n",
        "'[\"user1\", \"user2\" ... ]'\n",
        "```\n",
        "\n",
        "to\n",
        "\n",
        "```python\n",
        "[\"user1\", \"user2\" ... ]\n",
        "```\n",
        "\n",
        "**What to implement:** Implement a function `transform_faves(df)` which takes as input the original dataframe and returns the same dataframe, but with one additional column called `subr_faved_by_as_list`, where you have the same information as in `subr_faved_by`, but as a python list instead of a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RJLEddGE56qw",
        "outputId": "4ea2c6dc-82bc-4f1d-ef2d-0bbb67af0cc5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a285fd5f-0da7-4fb8-8f17-9784a4353dfd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>posted_at</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>selftext</th>\n",
              "      <th>subr_created_at</th>\n",
              "      <th>subr_description</th>\n",
              "      <th>subr_faved_by</th>\n",
              "      <th>subr_numb_members</th>\n",
              "      <th>subr_numb_posts</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>total_awards_received</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>user_num_posts</th>\n",
              "      <th>user_registered_at</th>\n",
              "      <th>user_upvote_ratio</th>\n",
              "      <th>subr_faved_by_as_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-08-17 20:26:04</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>BREAKING: Trump to begin hiding in mailboxes t...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "      <td>[vergil_never_cry, Jelegend, pianoyeah, salomo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-07-06 17:01:48</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>Joe Biden's America</td>\n",
              "      <td>0</td>\n",
              "      <td>0.67</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "      <td>[vergil_never_cry, Jelegend, pianoyeah, salomo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-09-09 02:29:02</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>4 more years and we can erase his legacy for g...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "      <td>[vergil_never_cry, Jelegend, pianoyeah, salomo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-06-23 23:02:39</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>Revelation 9:6 [Transhumanism: The New Religio...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "      <td>[vergil_never_cry, Jelegend, pianoyeah, salomo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-Howitzer-</td>\n",
              "      <td>2020-08-07 04:13:53</td>\n",
              "      <td>32</td>\n",
              "      <td>622</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-29</td>\n",
              "      <td>Subreddit about Donald Trump</td>\n",
              "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
              "      <td>30053</td>\n",
              "      <td>796986</td>\n",
              "      <td>donaldtrump</td>\n",
              "      <td>LOOK HERE, FAT</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>4661</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>-0.658599</td>\n",
              "      <td>[vergil_never_cry, Jelegend, pianoyeah, salomo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19935</th>\n",
              "      <td>zqrwiel</td>\n",
              "      <td>2020-07-23 16:39:15</td>\n",
              "      <td>11</td>\n",
              "      <td>246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-13</td>\n",
              "      <td>A subreddit dedicated to the discussion of hip...</td>\n",
              "      <td>['solex125', 'redreddington22', 'HibikiSS', 'k...</td>\n",
              "      <td>8740</td>\n",
              "      <td>630857</td>\n",
              "      <td>playboicarti</td>\n",
              "      <td>carti why</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1883</td>\n",
              "      <td>2014-02-12</td>\n",
              "      <td>0.861626</td>\n",
              "      <td>[solex125, redreddington22, HibikiSS, klondipe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19936</th>\n",
              "      <td>zqrwiel</td>\n",
              "      <td>2020-12-15 11:25:07</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>Then I think we might get 18 songs, outro usua...</td>\n",
              "      <td>2009-04-13</td>\n",
              "      <td>A subreddit dedicated to the discussion of hip...</td>\n",
              "      <td>['solex125', 'redreddington22', 'HibikiSS', 'k...</td>\n",
              "      <td>8740</td>\n",
              "      <td>630857</td>\n",
              "      <td>playboicarti</td>\n",
              "      <td>If uzi on track 3 and 16</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1883</td>\n",
              "      <td>2014-02-12</td>\n",
              "      <td>0.861626</td>\n",
              "      <td>[solex125, redreddington22, HibikiSS, klondipe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19937</th>\n",
              "      <td>zqrwiel</td>\n",
              "      <td>2020-12-27 13:57:49</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>He has 25songs to perform plus the additional ...</td>\n",
              "      <td>2009-04-13</td>\n",
              "      <td>A subreddit dedicated to the discussion of hip...</td>\n",
              "      <td>['solex125', 'redreddington22', 'HibikiSS', 'k...</td>\n",
              "      <td>8740</td>\n",
              "      <td>630857</td>\n",
              "      <td>playboicarti</td>\n",
              "      <td>Man carti’s concerts are gonna be long af</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1883</td>\n",
              "      <td>2014-02-12</td>\n",
              "      <td>0.861626</td>\n",
              "      <td>[solex125, redreddington22, HibikiSS, klondipe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19938</th>\n",
              "      <td>zqrwiel</td>\n",
              "      <td>2020-12-29 12:07:10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>I got goose[***]ps just by thinking about it 😬</td>\n",
              "      <td>2009-04-13</td>\n",
              "      <td>A subreddit dedicated to the discussion of hip...</td>\n",
              "      <td>['solex125', 'redreddington22', 'HibikiSS', 'k...</td>\n",
              "      <td>8740</td>\n",
              "      <td>630857</td>\n",
              "      <td>playboicarti</td>\n",
              "      <td>Can’t wait to see Carti going full rage mode o...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1883</td>\n",
              "      <td>2014-02-12</td>\n",
              "      <td>0.861626</td>\n",
              "      <td>[solex125, redreddington22, HibikiSS, klondipe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19939</th>\n",
              "      <td>zqrwiel</td>\n",
              "      <td>2021-01-21 16:47:13</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-04-13</td>\n",
              "      <td>A subreddit dedicated to the discussion of hip...</td>\n",
              "      <td>['solex125', 'redreddington22', 'HibikiSS', 'k...</td>\n",
              "      <td>8740</td>\n",
              "      <td>630857</td>\n",
              "      <td>playboicarti</td>\n",
              "      <td>[OFFTOPIC] have you seen that new LV? 😂💀</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1883</td>\n",
              "      <td>2014-02-12</td>\n",
              "      <td>0.861626</td>\n",
              "      <td>[solex125, redreddington22, HibikiSS, klondipe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19940 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a285fd5f-0da7-4fb8-8f17-9784a4353dfd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a285fd5f-0da7-4fb8-8f17-9784a4353dfd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a285fd5f-0da7-4fb8-8f17-9784a4353dfd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           author            posted_at  num_comments  score  \\\n",
              "0      -Howitzer-  2020-08-17 20:26:04            19      1   \n",
              "1      -Howitzer-  2020-07-06 17:01:48             1      3   \n",
              "2      -Howitzer-  2020-09-09 02:29:02             3      1   \n",
              "3      -Howitzer-  2020-06-23 23:02:39             2      1   \n",
              "4      -Howitzer-  2020-08-07 04:13:53            32    622   \n",
              "...           ...                  ...           ...    ...   \n",
              "19935     zqrwiel  2020-07-23 16:39:15            11    246   \n",
              "19936     zqrwiel  2020-12-15 11:25:07            39      1   \n",
              "19937     zqrwiel  2020-12-27 13:57:49            15      1   \n",
              "19938     zqrwiel  2020-12-29 12:07:10             6      1   \n",
              "19939     zqrwiel  2021-01-21 16:47:13            23      1   \n",
              "\n",
              "                                                selftext subr_created_at  \\\n",
              "0                                                    NaN      2009-04-29   \n",
              "1                                                    NaN      2009-04-29   \n",
              "2                                                    NaN      2009-04-29   \n",
              "3                                                    NaN      2009-04-29   \n",
              "4                                                    NaN      2009-04-29   \n",
              "...                                                  ...             ...   \n",
              "19935                                                NaN      2009-04-13   \n",
              "19936  Then I think we might get 18 songs, outro usua...      2009-04-13   \n",
              "19937  He has 25songs to perform plus the additional ...      2009-04-13   \n",
              "19938     I got goose[***]ps just by thinking about it 😬      2009-04-13   \n",
              "19939                                                NaN      2009-04-13   \n",
              "\n",
              "                                        subr_description  \\\n",
              "0                           Subreddit about Donald Trump   \n",
              "1                           Subreddit about Donald Trump   \n",
              "2                           Subreddit about Donald Trump   \n",
              "3                           Subreddit about Donald Trump   \n",
              "4                           Subreddit about Donald Trump   \n",
              "...                                                  ...   \n",
              "19935  A subreddit dedicated to the discussion of hip...   \n",
              "19936  A subreddit dedicated to the discussion of hip...   \n",
              "19937  A subreddit dedicated to the discussion of hip...   \n",
              "19938  A subreddit dedicated to the discussion of hip...   \n",
              "19939  A subreddit dedicated to the discussion of hip...   \n",
              "\n",
              "                                           subr_faved_by  subr_numb_members  \\\n",
              "0      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "1      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "2      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "3      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "4      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
              "...                                                  ...                ...   \n",
              "19935  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
              "19936  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
              "19937  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
              "19938  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
              "19939  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
              "\n",
              "       subr_numb_posts     subreddit  \\\n",
              "0               796986   donaldtrump   \n",
              "1               796986   donaldtrump   \n",
              "2               796986   donaldtrump   \n",
              "3               796986   donaldtrump   \n",
              "4               796986   donaldtrump   \n",
              "...                ...           ...   \n",
              "19935           630857  playboicarti   \n",
              "19936           630857  playboicarti   \n",
              "19937           630857  playboicarti   \n",
              "19938           630857  playboicarti   \n",
              "19939           630857  playboicarti   \n",
              "\n",
              "                                                   title  \\\n",
              "0      BREAKING: Trump to begin hiding in mailboxes t...   \n",
              "1                                    Joe Biden's America   \n",
              "2      4 more years and we can erase his legacy for g...   \n",
              "3      Revelation 9:6 [Transhumanism: The New Religio...   \n",
              "4                                         LOOK HERE, FAT   \n",
              "...                                                  ...   \n",
              "19935                                          carti why   \n",
              "19936                           If uzi on track 3 and 16   \n",
              "19937          Man carti’s concerts are gonna be long af   \n",
              "19938  Can’t wait to see Carti going full rage mode o...   \n",
              "19939           [OFFTOPIC] have you seen that new LV? 😂💀   \n",
              "\n",
              "       total_awards_received  upvote_ratio  user_num_posts user_registered_at  \\\n",
              "0                          0          1.00            4661         2012-11-09   \n",
              "1                          0          0.67            4661         2012-11-09   \n",
              "2                          0          1.00            4661         2012-11-09   \n",
              "3                          0          1.00            4661         2012-11-09   \n",
              "4                          0          0.88            4661         2012-11-09   \n",
              "...                      ...           ...             ...                ...   \n",
              "19935                      0          1.00            1883         2014-02-12   \n",
              "19936                      0          1.00            1883         2014-02-12   \n",
              "19937                      0          1.00            1883         2014-02-12   \n",
              "19938                      0          1.00            1883         2014-02-12   \n",
              "19939                      0          1.00            1883         2014-02-12   \n",
              "\n",
              "       user_upvote_ratio                              subr_faved_by_as_list  \n",
              "0              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...  \n",
              "1              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...  \n",
              "2              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...  \n",
              "3              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...  \n",
              "4              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...  \n",
              "...                  ...                                                ...  \n",
              "19935           0.861626  [solex125, redreddington22, HibikiSS, klondipe...  \n",
              "19936           0.861626  [solex125, redreddington22, HibikiSS, klondipe...  \n",
              "19937           0.861626  [solex125, redreddington22, HibikiSS, klondipe...  \n",
              "19938           0.861626  [solex125, redreddington22, HibikiSS, klondipe...  \n",
              "19939           0.861626  [solex125, redreddington22, HibikiSS, klondipe...  \n",
              "\n",
              "[19940 rows x 18 columns]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def transform_faves(df):\n",
        "    # your code here\n",
        "    subr_faved_by_as_list = np.empty(len(df), dtype=object)\n",
        "    for x in range(0,len(df)):\n",
        "        subr_faved_by_as_list[x] = literal_eval(df[\"subr_faved_by\"][x])\n",
        "    df[\"subr_faved_by_as_list\"] = subr_faved_by_as_list\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = transform_faves(df)\n",
        "df\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yhZ3u5aS3rrm"
      },
      "source": [
        "### P1.1.2 - Merge titles and text bodies\n",
        "\n",
        "All Reddit posts need to have a title, but a text body is optional. However, we want to be able to access all free text information for each post without having to look at two columns every time.\n",
        "\n",
        "**What to implement**: A function `concat(df)` that will take as input the original dataframe and will return it with an additional column called `full_text`, which will concatenate `title` and `selftext` columns, but with the following restrictions:\n",
        "\n",
        "- 1) Wrap the title between `<title>` and `</title>` tags.\n",
        "- 2) Add a new line (`\\n`) between title and selftext, but only in cases where you have both values (see instruction 4).\n",
        "- 3) Wrap the selftext between `<selftext>` and `</selftext>`.\n",
        "- 4) You **must not** include the tags in points (1) or (3) if the values for these columns is missing. We will consider a missing value either an empty value (empty string) or a string of only one character (e.g., an emoji). Also, the value of a `full_text` column must not end in the new line character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "RsmY-JB39N2m",
        "outputId": "6c9211a1-6814-41d2-a3c7-5fd96d15192b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-667f6c70d271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-667f6c70d271>\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<title>'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'</title>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<title>'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'</title>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selftext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selftext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<selftext>'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selftext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'</selftext>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def concat(df):\n",
        "    # your code here\n",
        "    for x in range(0,len(df)):\n",
        "        np.where(df['title'].values != '','<title>' + df['title'].values + '</title>', '')\n",
        "        np.where(df['title'].values != '','<title>' + df['title'].values + '</title>', '') + np.where(((df['title'].values != '') & (df['selftext'].values != '')), '\\n' , '') +  np.where(df['selftext'].values != '','<selftext>' + str(df['selftext'].values) + '</selftext>', '')\n",
        "    return df\n",
        "\n",
        "df = concat(df)\n",
        "print(df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ADWvbAIe4TVd"
      },
      "source": [
        "### P1.1.3 - Enrich posts \n",
        "\n",
        "We would like to augment our text data with linguistic information. To this end, we will _tokenize_, apply _part-of-speech tagging_, and then we will _lower case_ all the posts.\n",
        "\n",
        "**What to implement**: A function `enrich_posts(df)` that will take as input the original dataframe and will return it with **two** additional columns: `enriched_title` and `enriched_selftext`. These columns will contain tokenized, pos-tagged and lower cased versions of the original text. **You must implement them in this order**, because the pos tagger uses casing information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nDnaSwI46T_",
        "outputId": "2e6f2547-861a-45f9-9a1a-3caafd2c7260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           author            posted_at  num_comments  score  \\\n",
            "0      -Howitzer-  2020-08-17 20:26:04            19      1   \n",
            "1      -Howitzer-  2020-07-06 17:01:48             1      3   \n",
            "2      -Howitzer-  2020-09-09 02:29:02             3      1   \n",
            "3      -Howitzer-  2020-06-23 23:02:39             2      1   \n",
            "4      -Howitzer-  2020-08-07 04:13:53            32    622   \n",
            "...           ...                  ...           ...    ...   \n",
            "19935     zqrwiel  2020-07-23 16:39:15            11    246   \n",
            "19936     zqrwiel  2020-12-15 11:25:07            39      1   \n",
            "19937     zqrwiel  2020-12-27 13:57:49            15      1   \n",
            "19938     zqrwiel  2020-12-29 12:07:10             6      1   \n",
            "19939     zqrwiel  2021-01-21 16:47:13            23      1   \n",
            "\n",
            "                                                selftext subr_created_at  \\\n",
            "0                                                    NaN      2009-04-29   \n",
            "1                                                    NaN      2009-04-29   \n",
            "2                                                    NaN      2009-04-29   \n",
            "3                                                    NaN      2009-04-29   \n",
            "4                                                    NaN      2009-04-29   \n",
            "...                                                  ...             ...   \n",
            "19935                                                NaN      2009-04-13   \n",
            "19936  Then I think we might get 18 songs, outro usua...      2009-04-13   \n",
            "19937  He has 25songs to perform plus the additional ...      2009-04-13   \n",
            "19938     I got goose[***]ps just by thinking about it 😬      2009-04-13   \n",
            "19939                                                NaN      2009-04-13   \n",
            "\n",
            "                                        subr_description  \\\n",
            "0                           Subreddit about Donald Trump   \n",
            "1                           Subreddit about Donald Trump   \n",
            "2                           Subreddit about Donald Trump   \n",
            "3                           Subreddit about Donald Trump   \n",
            "4                           Subreddit about Donald Trump   \n",
            "...                                                  ...   \n",
            "19935  A subreddit dedicated to the discussion of hip...   \n",
            "19936  A subreddit dedicated to the discussion of hip...   \n",
            "19937  A subreddit dedicated to the discussion of hip...   \n",
            "19938  A subreddit dedicated to the discussion of hip...   \n",
            "19939  A subreddit dedicated to the discussion of hip...   \n",
            "\n",
            "                                           subr_faved_by  subr_numb_members  \\\n",
            "0      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
            "1      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
            "2      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
            "3      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
            "4      ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
            "...                                                  ...                ...   \n",
            "19935  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
            "19936  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
            "19937  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
            "19938  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
            "19939  ['solex125', 'redreddington22', 'HibikiSS', 'k...               8740   \n",
            "\n",
            "       subr_numb_posts     subreddit  \\\n",
            "0               796986   donaldtrump   \n",
            "1               796986   donaldtrump   \n",
            "2               796986   donaldtrump   \n",
            "3               796986   donaldtrump   \n",
            "4               796986   donaldtrump   \n",
            "...                ...           ...   \n",
            "19935           630857  playboicarti   \n",
            "19936           630857  playboicarti   \n",
            "19937           630857  playboicarti   \n",
            "19938           630857  playboicarti   \n",
            "19939           630857  playboicarti   \n",
            "\n",
            "                                                   title  \\\n",
            "0      BREAKING: Trump to begin hiding in mailboxes t...   \n",
            "1                                    Joe Biden's America   \n",
            "2      4 more years and we can erase his legacy for g...   \n",
            "3      Revelation 9:6 [Transhumanism: The New Religio...   \n",
            "4                                         LOOK HERE, FAT   \n",
            "...                                                  ...   \n",
            "19935                                          carti why   \n",
            "19936                           If uzi on track 3 and 16   \n",
            "19937          Man carti’s concerts are gonna be long af   \n",
            "19938  Can’t wait to see Carti going full rage mode o...   \n",
            "19939           [OFFTOPIC] have you seen that new LV? 😂💀   \n",
            "\n",
            "       total_awards_received  upvote_ratio  user_num_posts user_registered_at  \\\n",
            "0                          0          1.00            4661         2012-11-09   \n",
            "1                          0          0.67            4661         2012-11-09   \n",
            "2                          0          1.00            4661         2012-11-09   \n",
            "3                          0          1.00            4661         2012-11-09   \n",
            "4                          0          0.88            4661         2012-11-09   \n",
            "...                      ...           ...             ...                ...   \n",
            "19935                      0          1.00            1883         2014-02-12   \n",
            "19936                      0          1.00            1883         2014-02-12   \n",
            "19937                      0          1.00            1883         2014-02-12   \n",
            "19938                      0          1.00            1883         2014-02-12   \n",
            "19939                      0          1.00            1883         2014-02-12   \n",
            "\n",
            "       user_upvote_ratio                              subr_faved_by_as_list  \\\n",
            "0              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...   \n",
            "1              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...   \n",
            "2              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...   \n",
            "3              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...   \n",
            "4              -0.658599  [vergil_never_cry, Jelegend, pianoyeah, salomo...   \n",
            "...                  ...                                                ...   \n",
            "19935           0.861626  [solex125, redreddington22, HibikiSS, klondipe...   \n",
            "19936           0.861626  [solex125, redreddington22, HibikiSS, klondipe...   \n",
            "19937           0.861626  [solex125, redreddington22, HibikiSS, klondipe...   \n",
            "19938           0.861626  [solex125, redreddington22, HibikiSS, klondipe...   \n",
            "19939           0.861626  [solex125, redreddington22, HibikiSS, klondipe...   \n",
            "\n",
            "                                          enriched_title  \n",
            "0      [(BREAKING, NN), (:, :), (Trump, NN), (to, TO)...  \n",
            "1      [(Joe, NNP), (Biden, NNP), ('s, POS), (America...  \n",
            "2      [(4, CD), (more, JJR), (years, NNS), (and, CC)...  \n",
            "3      [(Revelation, NN), (9:6, CD), ([, JJ), (Transh...  \n",
            "4         [(LOOK, NNP), (HERE, NNP), (,, ,), (FAT, NNP)]  \n",
            "...                                                  ...  \n",
            "19935                          [(carti, NN), (why, WRB)]  \n",
            "19936  [(If, IN), (uzi, JJ), (on, IN), (track, NN), (...  \n",
            "19937  [(Man, NNP), (carti, VBZ), (’, JJ), (s, NN), (...  \n",
            "19938  [(Can, MD), (’, VB), (t, JJ), (wait, NN), (to,...  \n",
            "19939  [([, JJ), (OFFTOPIC, NNP), (], NN), (have, VBP...  \n",
            "\n",
            "[19940 rows x 19 columns]\n"
          ]
        }
      ],
      "source": [
        "def enrich_posts(df):\n",
        "    df['enriched_title'] = df['title'].apply(word_tokenize).apply(pos_tag)  #used postag as it \n",
        "    tlist = [[(j.lower(),k) for (j,k) in i] for i in df['enriched_title']]  #list comp\n",
        "    df['enriched_title'] = df['title']\n",
        "    df['enriched_title'] = df['enriched_title'].apply(word_tokenize)\n",
        "    df['enriched_title'] = df['enriched_title'].apply(pos_tag)\n",
        "    return df\n",
        "\n",
        "df = enrich_posts(df)\n",
        "print(df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I8E010UbQyML"
      },
      "source": [
        "## P1.2 - Answering questions with pandas\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZmG2VIYQ93I"
      },
      "source": [
        "### P1.2.1 - Users with best scores\n",
        "\n",
        "- Find the users with the highest aggregate scores (over all their posts) for the whole dataset. You should restrict your results to only those whose aggregated score is above 10,000 points, in descending order. Your code should generate a dictionary of the form `{author:aggregated_scores ... }`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhW8Rr6QSXDj",
        "outputId": "e060b02b-697a-4481-ad15-af9d79da9f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'DaFunkJunkie': 250375, 'None': 218846, 'SUPERGUESSOUS': 211611, 'jigsawmap': 210824, 'chrisdh79': 143538, 'hildebrand_rarity': 122464, 'iSlingShlong': 118595, 'hilltopye': 81245, 'tefunka': 79560, 'OldFashionedJizz': 64398, 'JLBesq1981': 58235, 'rspix000': 57107, 'Wagamaga': 47989, 'stem12345679': 47455, 'TheJeck': 26058, 'TheGamerDanYT': 25357, 'TrumpSharted': 21154, 'NotsoPG': 18518, 'SonictheManhog': 18116, 'BlanketMage': 13677, 'NewAltWhoThis': 12771, 'kevinmrr': 11900, 'Dajakesta0624': 11613, 'apocalypticalley': 10382}\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "agg_score = df.groupby([\"author\"]).score.sum().reset_index()\n",
        "score_vals = np.where(agg_score.score > 10000)\n",
        "agg_score_df = agg_score.iloc[score_vals]\n",
        "agg_score_df = agg_score_df.sort_values(by=['score'],ascending=False)\n",
        "authors = np.asarray(agg_score_df['author'])\n",
        "score = np.asarray(agg_score_df['score'])\n",
        "dicts = {}\n",
        "for i in range(len(authors)):\n",
        "    dicts[authors[i]] = score[i]\n",
        "print(dicts)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "woOFrPFQT5cZ"
      },
      "source": [
        "### P1.2.2 - Awarded posts\n",
        "\n",
        "Find the number of posts that have received at least one award. Your query should return only one value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fVuaWmmUGVW",
        "outputId": "54e810b0-e44b-46f6-c5c2-c8343a13721e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Total Post with atleast 1 award:119\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# your code here\n",
        "Total_post = (df['total_awards_received']!=0).sum()\n",
        "print(\" Total Post with atleast 1 award:\" + str(Total_post))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uVj1WikSUPjO"
      },
      "source": [
        "### P1.2.3 Find Covid \n",
        "\n",
        "Find the name and description of all subreddits where the name starts with `Covid` or `Corona` and the description contains `covid` or `Covid` anywhere. Your code should generate a dictionary of the form#\n",
        "\n",
        "```python\n",
        "  {'Coronavirus':'Place to discuss all things COVID-related',\n",
        "  ...\n",
        "  }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6fIWO8BUhu3",
        "outputId": "dda72fec-64aa-4c13-9ce8-1aee202aef34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'CoronavirusCA': 'Tracking the Coronavirus/Covid-19 outbreak in California'}\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "df_val = df.loc[(df['subreddit'].str.startswith('Covid')== True) | (df['subreddit'].str.startswith('Corona')== True)]\n",
        "\n",
        "covid_post = df_val.loc[(df_val['subr_description'].str.contains('Covid')== True) | (df_val['subr_description'].str.contains('covid')== True)]\n",
        "covid_post_subredit = np.asarray(covid_post['subreddit'])\n",
        "covid_post_subr_description = np.asarray(covid_post['subr_description'])\n",
        "dicts = {}\n",
        "\n",
        "for i in range(len(covid_post_subredit)):\n",
        "    dicts[covid_post_subredit[i]] = covid_post_subr_description[i]\n",
        "print(dicts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToPttp2-fsXG"
      },
      "source": [
        "### P1.2.4 - Redditors that favorite the most\n",
        "\n",
        "Find the users that have favorited the largest number of subreddits. You must produce a pandas dataframe with **two** columns, with the following format:\n",
        "\n",
        "```python\n",
        "     redditor\t    numb_favs\n",
        "0\tuser1           7\n",
        "1\tuser2           6\n",
        "2\tuser3\t       5\n",
        "3\tuser4           4\n",
        "...\n",
        "```\n",
        "\n",
        "where the first column is a Redditor username and the second column is the number of distinct subreddits he/she has favorited."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JxR1ozHouIlO",
        "outputId": "6189154f-3e25-4fdd-bb2c-a7129c8e29cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ce1407d5-9eac-4244-8549-35e3de12b2f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>redditor</th>\n",
              "      <th>numb_favs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>JordanCarter77</td>\n",
              "      <td>5485.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>Peninsula99999</td>\n",
              "      <td>5171.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>Zhana-Aul</td>\n",
              "      <td>5160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>Kdog8273</td>\n",
              "      <td>4079.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>Mcnst</td>\n",
              "      <td>3968.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce1407d5-9eac-4244-8549-35e3de12b2f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce1407d5-9eac-4244-8549-35e3de12b2f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce1407d5-9eac-4244-8549-35e3de12b2f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            redditor  numb_favs\n",
              "1230  JordanCarter77     5485.0\n",
              "350   Peninsula99999     5171.0\n",
              "515        Zhana-Aul     5160.0\n",
              "1239        Kdog8273     4079.0\n",
              "290            Mcnst     3968.0"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "redditor = df['author'].unique()\n",
        "num_favs = np.empty(len(redditor), dtype=float)\n",
        "reddi_name = np.empty(len(redditor), dtype=object)\n",
        "ct = 0\n",
        "for reddi in redditor:\n",
        "    df_faved_subred =  df.loc[(df['subr_faved_by'].str.contains(reddi) == True )]\n",
        "    val = len(df_faved_subred)\n",
        "    num_favs[ct] = val\n",
        "    reddi_name[ct] = reddi\n",
        "    ct = ct+1\n",
        "\n",
        "df_fav_red = list(zip(reddi_name, num_favs))\n",
        "df_output = pd.DataFrame(df_fav_red,\n",
        "                  columns = ['redditor', 'numb_favs']) \n",
        "df_final = df_output.sort_values(by=['numb_favs'], ascending=False)\n",
        "df_final.head(5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Adrian_Part1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
